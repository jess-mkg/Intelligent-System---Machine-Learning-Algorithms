{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/Jessica/Desktop/Coding/School/2802ICT/Assignment2')\n",
    "\n",
    "from imports import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:     #this class creats an object for each node in the tree\n",
    "\n",
    "    def __init__(self, feature=None, thresh=None, left=None, right=None, *, value=None):        \n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.right_child = right\n",
    "        self.left_child = left\n",
    "        self.thresh = thresh\n",
    "        self.labels = []\n",
    "\n",
    "    def isNode(self):\n",
    "        if self.value is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTree: \n",
    "\n",
    "    def __init__(self, data, max_depth, min_split = 2, num_feats = None):\n",
    "        self. df = data\n",
    "\n",
    "        self.feature_train = []\n",
    "        self.feature_test = []\n",
    "        self.target_train = []\n",
    "        self.target_test = []\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_split = min_split\n",
    "        #given dataset has 6 features but can use datasets\n",
    "        self.num_feats = num_feats \n",
    "        self.root = None\n",
    "\n",
    "    def driver(self, split):\n",
    "\n",
    "        self.split_data(split)\n",
    "        self.fit(self.feature_train, self.target_train)\n",
    "\n",
    "        prediction_train = self.predict(self.feature_train)\n",
    "        \n",
    "        percent_train = self.accuracy(self.target_train, prediction_train)\n",
    "\n",
    "    def predict(self, features):\n",
    "        return np.array([self.traverse(x, self.root) for x in features])       # traverses the tree to find the best splits\n",
    "\n",
    "    def traverse(self, x, node):\n",
    "        #if it is a node return its value\n",
    "        if node.isNode():\n",
    "            #return the value           \n",
    "            return node.value\n",
    "         # x is the current value\n",
    "         # feature train, it will recursively search for the split and \n",
    "         # threshold over the children to find the most optimal splits   \n",
    "        if x[node.feature] <= node.thresh:                  \n",
    "            return self.traverse(x, node.left_child)\n",
    "        return self.traverse(x, node.right_child)                      \n",
    "    \n",
    "    def accuracy(self, actual, prediction):\n",
    "        res = self.confusion_matrix(actual, prediction)\n",
    "        self.calc(res)\n",
    "        #accuracy = (self.counter(actual, prediction))/len(actual)\n",
    "        #return accuracy\n",
    "\n",
    "    def confusion_matrix(self, actual, prediction):\n",
    "        classes = np.unique(actual)\n",
    "        K = len(classes)\n",
    "        result = np.zeros((K, K))\n",
    "\n",
    "        for i in range(len(actual)):\n",
    "            \n",
    "            if actual[i] == \"unacc\":\n",
    "                index = 0\n",
    "                if prediction[i] == \"unacc\":\n",
    "                    result[index][0] += 1\n",
    "                elif prediction[i] == \"acc\":\n",
    "                    result[index][1] += 1\n",
    "                elif prediction[i] == \"good\":\n",
    "                    result[index][2] += 1\n",
    "                elif prediction[i] == \"vgood\":\n",
    "                    result[index][3] += 1\n",
    "            \n",
    "            elif actual[i] == 'acc':\n",
    "                index = 1\n",
    "                if prediction[i] == 'unacc':\n",
    "                    result[index][0] += 1\n",
    "                elif prediction[i] == 'acc':\n",
    "                    result[index][1] += 1\n",
    "                elif prediction[i] == 'good':\n",
    "                    result[index][2] += 1\n",
    "                elif prediction[i] == 'vgood':\n",
    "                    result[index][3] += 1\n",
    "\n",
    "            elif actual[i] == 'good':\n",
    "                index = 2\n",
    "                if prediction[i] == 'unacc':\n",
    "                    result[index][0] += 1\n",
    "                elif prediction[i] == 'acc':\n",
    "                    result[index][1] += 1\n",
    "                elif prediction[i] == 'good':\n",
    "                    result[index][2] += 1\n",
    "                elif prediction[i] == 'vgood':\n",
    "                    result[index][3] += 1\n",
    "\n",
    "            elif actual[i] == 'vgood':\n",
    "                index = 3\n",
    "                if prediction[i] == 'unacc':\n",
    "                    result[index][0] += 1\n",
    "                elif prediction[i] == 'acc':\n",
    "                    result[index][1] += 1\n",
    "                elif prediction[i] == 'good':\n",
    "                    result[index][2] += 1\n",
    "                elif prediction[i] == 'vgood':\n",
    "                    result[index][3] += 1\n",
    "     \n",
    "        return result\n",
    "\n",
    "    def calc(self, result):\n",
    "        \n",
    "        size = len(result)\n",
    "        locations = np.zeros((size, size))\n",
    "        tp = tn = fp = fn = 0\n",
    "\n",
    "        for i in range(size):\n",
    "            if locations[i][i] != 1:\n",
    "                tp += result[i][i]\n",
    "                locations[i][i] = 1\n",
    "            for j in range(size): \n",
    "                if locations[i][j] != 1:\n",
    "                    fp += (result[i][0] + result[i][1] + result[i][2] + result[i][3] - result[i][i])\n",
    "                    locations[i][0] = locations[i][1] = locations[i][2] = locations[i][3] = 1\n",
    "            for j in range(size):    \n",
    "                if locations[i][j] != 1:\n",
    "                    fn += (result[0][i] + result[1][i] + result[2][i] + result[3][i] - result[i][i])\n",
    "                    locations[0][i] = locations[1][i] = locations[2][i] = locations[3][i] = 1\n",
    "            for j in range(size):    \n",
    "                if locations[i][j] != 1:\n",
    "                    tn += result[i][j]\n",
    "                    locations[i][j] = 1\n",
    "            \n",
    "            print(locations)\n",
    "            locations = np.zeros((size, size))\n",
    "\n",
    "        print( tp, tn, fp, fn)\n",
    "\n",
    "\n",
    "        p = (tp)/(tp+fp)\n",
    "        print(\"Precision: \",p)\n",
    "        r = (tp)/(tp+fn)\n",
    "        print(\"Recall: \",r)\n",
    "        f1 = 2/((1/p)+(1/r))\n",
    "        print(\"F1 Score: \",f1)\n",
    "\n",
    "             \n",
    "    def fit(self, feature_train, target_train):\n",
    "\n",
    "        self.num_feats = feature_train.shape[1]\n",
    "        self.root = self.build_tree(feature_train, target_train)\n",
    "\n",
    "    #builds the tree recursively\n",
    "    def build_tree(self, f_train, t_train, depth = 0):\n",
    "        \n",
    "        #amount of samples in dataset\n",
    "        num_samples = f_train.shape[0]\n",
    "        #amount of features\n",
    "        num_feats = self.num_feats\n",
    "        #num of labels -> (acc/unacc/good/vgood)\n",
    "        n_labels = len(np.unique(t_train))\n",
    "        #criteria that end the searching\n",
    "        if (depth >= self.max_depth or n_labels == 1 or num_samples < self.min_split):\n",
    "            leaf = self.high_freq(t_train)             \n",
    "            return Node(value = leaf)\n",
    "        \n",
    "        feature_ids = np.random.choice(num_feats, self.num_feats, replace=False)\n",
    "        \n",
    "        if f_train.size != 0 and t_train.size != 0:\n",
    "            # finds the best feature to split on and the threshold\n",
    "            best_feature, threshold = self.best_split(f_train, t_train, feature_ids)\n",
    "            left_id, right_id = self.next_split(f_train[:, best_feature], threshold)\n",
    "\n",
    "            left = self.build_tree(f_train[left_id,:], t_train[left_id], depth + 1)\n",
    "            right = self.build_tree(f_train[right_id,:], t_train[right_id], depth + 1)\n",
    "\n",
    "        return Node(best_feature, threshold, left, right)\n",
    "     \n",
    "    def best_split(self, f_train, t_train, f_ids):\n",
    "        \n",
    "        best_gain = -1\n",
    "        split_id, split_threshold = None, None\n",
    "        \n",
    "        for f_id in f_ids:\n",
    "            #f_id_col holds the column for 1 feature at a time\n",
    "            f_id_col = f_train[:, f_id]\n",
    "\n",
    "            #thresholds has the unique elements in each feature column\n",
    "            thresholds = np.unique(f_id_col)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                gain = self.info_gain(t_train, f_id_col, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "\n",
    "                    best_gain = gain\n",
    "                    split_id = f_id\n",
    "                    split_threshold = threshold\n",
    "\n",
    "        return split_id, split_threshold\n",
    "\n",
    "    def info_gain(self, t_train, feature_col, threshold):\n",
    "        #finds the entropy of the current set\n",
    "        parent_entropy = self.entropy(t_train)\n",
    "        #finds the left and right id values based on split\n",
    "        left_id, right_id = self.next_split(feature_col, threshold)\n",
    "\n",
    "        if len(left_id) == 0 or len(right_id) == 0:\n",
    "            return 0\n",
    "\n",
    "        n = len(t_train)\n",
    "        l_len, r_len = len(left_id), len(right_id)\n",
    "        l_entropy, r_entropy = self.entropy(t_train[left_id]), self.entropy(t_train[right_id])\n",
    "        child_entropy = (l_len/n) * l_entropy + (r_len/n) * r_entropy\n",
    "        info_gain_val = parent_entropy - child_entropy\n",
    "\n",
    "        return info_gain_val\n",
    "\n",
    "    def next_split(self, feature_col, threshold):\n",
    "        left_id = np.argwhere(feature_col <= threshold).flatten()\n",
    "        right_id = np.argwhere(feature_col > threshold).flatten()\n",
    "        return left_id, right_id\n",
    "    \n",
    "    #finds the entropy -> fequency/length \n",
    "    def entropy(self, t_train):\n",
    "        histogram = []\n",
    "        counted_vals = Counter(t_train)\n",
    "        for word in set(self.target_train):\n",
    "            new_val = counted_vals[word]\n",
    "            histogram.append(new_val)\n",
    "\n",
    "        histogram = np.array(histogram)\n",
    "        length = len(t_train)              \n",
    "        calc = histogram/length\n",
    "        \n",
    "        return -(np.sum([c * np.log2(c) for c in calc if c > 0]))\n",
    "\n",
    "    def split_data(self, split):\n",
    "        dataset = np.array(self.df)\n",
    "        #randomly shuffle dataset\n",
    "        np.random.shuffle(dataset)  \n",
    "\n",
    "        #multiply length by wanted percent and // 1 to ensure its a wh0le number\n",
    "        test_size = int((len(dataset)*split)//1)                      \n",
    "        train_size = int(len(dataset) - test_size)\n",
    "\n",
    "        #use the length to make respective lists\n",
    "        train = dataset[:train_size]                                     \n",
    "        test = dataset[test_size:]\n",
    "\n",
    "        #only want the last column. THEN map -> join as cars are strings\n",
    "        target_train = np.delete(train, np.s_[0:6], axis = 1)                  \n",
    "        self.target_train = np.array(list(map(''.join, target_train)))\n",
    "\n",
    "        self.feature_train = np.delete(train, 6, axis = 1)                  \n",
    "        #self.feature_train = np.array(list(map(''.join, feature_train)))\n",
    "\n",
    "        self.target_test = np.delete(test, np.s_[0:6], axis = 1)\n",
    "        #self.target_test = np.array(list(map(''.join, target_test)))\n",
    "\n",
    "        self.feature_test = np.delete(test, 6, axis = 1)\n",
    "        #self.feature_test = np.array(list(map(''.join, feature_test)))\n",
    "\n",
    "    def high_freq(self, target_train):   \n",
    "        counter = Counter(target_train)  \n",
    "        #most common value present which is useful when determing where to split  \n",
    "        most_common = counter.most_common(1)[0][0] \n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 1. 1.]]\n",
      "1127.0 0 169.0 0\n",
      "Precision:  0.8695987654320988\n",
      "Recall:  1.0\n",
      "F1 Score:  0.9302517540239373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #file is read from a class called SetUp\n",
    "    data = SetUp(\"car.csv\", {'buying':'string','maint':'string','doors':'string','persons':'string','lug_boot':'string','safety':'string','class':'string'}) \n",
    "\n",
    "    ####################### USER SETUP AREA #######################\n",
    "    \n",
    "    split = 0.25\n",
    "    max_depth = 5\n",
    "    print_each_k_percentage = False             #if you want to print each k's percentage    \n",
    "    \n",
    "    ####################### END OF USER SETUP #######################\n",
    "\n",
    "    DT = DecisionTree(data.df, max_depth)\n",
    "    DT.driver(split)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de8ad9456243b6960082ed76502daf77a564024d303d074cae540dad91fb49fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
