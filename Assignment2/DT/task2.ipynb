{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/Jessica/Desktop/Coding/School/2802ICT/Assignment2')\n",
    "\n",
    "from imports import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:     #this class creats an object for each node in the tree\n",
    "\n",
    "    def __init__(self, feature=None, thresh=None, left=None, right=None, *, value=None):        \n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.right_child = right\n",
    "        self.left_child = left\n",
    "        self.thresh = thresh\n",
    "        self.labels = []\n",
    "\n",
    "    def isNode(self):\n",
    "        if self.value is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DecisionTree: \n",
    "\n",
    "    def __init__(self, data, max_depth, min_split = 2, num_feats = None):\n",
    "        self. df = data\n",
    "\n",
    "        self.feature_train = []\n",
    "        self.feature_test = []\n",
    "        self.target_train = []\n",
    "        self.target_test = []\n",
    "\n",
    "        self.max_depth = max_depth\n",
    "        self.min_split = min_split\n",
    "        #given dataset has 6 features but can use datasets\n",
    "        self.num_feats = num_feats \n",
    "        self.root = None\n",
    "\n",
    "    def accuracy(self, split):\n",
    "\n",
    "        self.split_data(split)\n",
    "        self.fit()\n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        self.num_feats = self.feature_train.shape[1]\n",
    "        self.root = self.build_tree(self.feature_train, self.target_train)\n",
    "\n",
    "    #builds the tree recursively\n",
    "    def build_tree(self, f_train, t_train, depth = 0):\n",
    "        \n",
    "        #amount of samples in dataset\n",
    "        num_samples = f_train.shape[0]\n",
    "        #amount of features\n",
    "        num_feats = self.num_feats\n",
    "        #num of labels -> (acc/unacc/good/vgood)\n",
    "        n_labels = len(np.unique(t_train))\n",
    "        #criteria that end the searching\n",
    "        if (depth >= self.max_depth or n_labels == 1 or num_samples < self.min_split):\n",
    "            leaf = self.high_freq(t_train)             \n",
    "            return Node(value = leaf)\n",
    "        \n",
    "        feature_ids = np.random.choice(num_feats, self.num_feats, replace=False)\n",
    "        \n",
    "        if f_train.size != 0 and t_train.size != 0:\n",
    "            # finds the best feature to split on and the threshold\n",
    "            best_feature, threshold = self.best_split(f_train, t_train, feature_ids)\n",
    "            \n",
    "            #where to split to children nodes\n",
    "            #left_id, right_id = self.child_split(f_train[:, best_feature], threshold)\n",
    "\n",
    "    def best_split(self, f_train, t_train, f_ids):\n",
    "        \n",
    "        best_gain = -1\n",
    "        split_id, split_threshold = None, None\n",
    "        \n",
    "        for f_id in f_ids:\n",
    "            #f_id_col holds the column for 1 feature at a time\n",
    "            f_id_col = f_train[:, f_id]\n",
    "\n",
    "            #thresholds has the unique elements in each feature column\n",
    "            thresholds = np.unique(f_id_col)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                gain = self.info_gain(t_train, f_id_col, threshold)\n",
    "\n",
    "                if gain > best_gain:\n",
    "\n",
    "                    best_gain = gain\n",
    "                    split_id = f_id\n",
    "                    split_threshold = threshold\n",
    "\n",
    "        return split_id, split_threshold\n",
    "\n",
    "\n",
    "    def info_gain(self, t_train, feature_col, threshold):\n",
    "        parent_entropy = self.entropy(t_train)\n",
    "        print(parent_entropy)\n",
    "        left_id, right_id = self.next_split(feature_col, threshold)\n",
    "\n",
    "    \n",
    "    #finds the entropy -> fequency/length \n",
    "    def entropy(self, t_train):\n",
    "        histogram = []\n",
    "        counted_vals = Counter(t_train)\n",
    "        for word in set(self.target_train):\n",
    "            new_val = counted_vals[word]\n",
    "            histogram.append(new_val)\n",
    "\n",
    "        histogram = np.array(histogram)\n",
    "        length = len(t_train)              \n",
    "        calc = histogram/length\n",
    "        \n",
    "        return -(np.sum([c * np.log2(c) for c in calc if c > 0]))\n",
    "\n",
    "\n",
    "    def split_data(self, split):\n",
    "        dataset = np.array(self.df)\n",
    "        #randomly shuffle dataset\n",
    "        np.random.shuffle(dataset)  \n",
    "\n",
    "        #multiply length by wanted percent and // 1 to ensure its a wh0le number\n",
    "        test_size = int((len(dataset)*split)//1)                      \n",
    "        train_size = int(len(dataset) - test_size)\n",
    "\n",
    "        #use the length to make respective lists\n",
    "        train = dataset[:train_size]                                     \n",
    "        test = dataset[test_size:]\n",
    "\n",
    "        #only want the last column. THEN map -> join as cars are strings\n",
    "        target_train = np.delete(train, np.s_[0:6], axis = 1)                  \n",
    "        self.target_train = np.array(list(map(''.join, target_train)))\n",
    "\n",
    "        self.feature_train = np.delete(train, 6, axis = 1)                  \n",
    "        #self.feature_train = np.array(list(map(''.join, feature_train)))\n",
    "\n",
    "        self.target_test = np.delete(test, np.s_[0:6], axis = 1)\n",
    "        #self.target_test = np.array(list(map(''.join, target_test)))\n",
    "\n",
    "        self.feature_test = np.delete(test, 6, axis = 1)\n",
    "        #self.feature_test = np.array(list(map(''.join, feature_test)))\n",
    "\n",
    "    def high_freq(self, target_train):   \n",
    "        counter = Counter(target_train)  \n",
    "        #most common value present which is useful when determing where to split  \n",
    "        most_common = counter.most_common(1)[0][0] \n",
    "        return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2117705715535723\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTree' object has no attribute 'next_split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-98df0b73b009>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mDT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mDT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-f48ffcf4c8ef>\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(self, split)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-f48ffcf4c8ef>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_feats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-f48ffcf4c8ef>\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(self, f_train, t_train, depth)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[1;31m# finds the best feature to split on and the threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mbest_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m             \u001b[1;31m#where to split to children nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-f48ffcf4c8ef>\u001b[0m in \u001b[0;36mbest_split\u001b[1;34m(self, f_train, t_train, f_ids)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthresholds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[0mgain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo_gain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_id_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgain\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbest_gain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-f48ffcf4c8ef>\u001b[0m in \u001b[0;36minfo_gain\u001b[1;34m(self, t_train, feature_col, threshold)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mparent_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mleft_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DecisionTree' object has no attribute 'next_split'"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #file is read from a class called SetUp\n",
    "    data = SetUp(\"car.csv\", {'buying':'string','maint':'string','doors':'string','persons':'string','lug_boot':'string','safety':'string','class':'string'}) \n",
    "\n",
    "    ####################### USER SETUP AREA #######################\n",
    "    \n",
    "    split = 0.25\n",
    "    max_depth = 5\n",
    "    print_each_k_percentage = False             #if you want to print each k's percentage    \n",
    "    \n",
    "    ####################### END OF USER SETUP #######################\n",
    "\n",
    "    DT = DecisionTree(data.df, max_depth)\n",
    "    DT.accuracy(split)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de8ad9456243b6960082ed76502daf77a564024d303d074cae540dad91fb49fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
